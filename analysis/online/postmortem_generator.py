"""
SPL-7a-D: Post-mortem è‡ªåŠ¨å½’å› 

å½“å‘ç”Ÿé£é™©äº‹ä»¶æ—¶è‡ªåŠ¨ç”Ÿæˆ post-mortem æŠ¥å‘Šã€‚
"""

import sys
import os
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
import json
import numpy as np
import pandas as pd

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
os.chdir(project_root)

from analysis.online.risk_signal_schema import RiskSignal, GatingEvent, AllocatorEvent
from analysis.online.risk_state_machine import RiskState, StateTransitionEvent
from analysis.replay_schema import ReplayOutput, load_replay_outputs


class PostMortemTriggerType(Enum):
    """Post-mortem è§¦å‘ç±»å‹"""
    GATE_TRIGGERED = "gate_triggered"           # Gate è§¦å‘
    ENVELOPE_TOUCHED = "envelope_touched"       # Envelope è¢«è§¦åŠ
    SPIKE_ANOMALY = "spike_anomaly"             # å¼‚å¸¸ spike
    CO_CRASH = "co_crash"                       # Co-crash
    STATE_CRITICAL = "state_critical"           # çŠ¶æ€è½¬ä¸ºä¸¥é‡
    MANUAL = "manual"                           # æ‰‹åŠ¨è§¦å‘


@dataclass
class PostMortemReport:
    """Post-mortem æŠ¥å‘Š"""
    report_id: str
    trigger_type: PostMortemTriggerType
    strategy_id: str

    # æ—¶é—´ä¿¡æ¯
    trigger_time: datetime
    window_start: datetime
    window_end: datetime

    # è§¦å‘ä¸Šä¸‹æ–‡
    trigger_event: Dict[str, Any]

    # å…³é”®æŒ‡æ ‡å˜åŒ–è½¨è¿¹
    metrics_trajectory: List[Dict[str, float]]

    # è§¦å‘çš„è§„åˆ™/çº¦æŸ
    triggered_rules: List[Dict[str, Any]]
    binding_constraints: List[Dict[str, Any]]

    # å¸‚åœºçŠ¶æ€åˆ¤æ–­
    regime_at_trigger: Dict[str, Any]

    # ç»Ÿè®¡ä¿¡æ¯
    statistics: Dict[str, Any]

    # å¯¹åº”çš„ replay ç‰‡æ®µæŒ‡é’ˆ
    replay_pointers: List[Dict[str, Any]]

    # å½’å› åˆ†æ
    root_cause_analysis: Dict[str, Any]

    # å»ºè®®
    recommendations: List[str]

    # å…ƒä¿¡æ¯
    generated_at: datetime = field(default_factory=datetime.now)
    version: str = "1.0"

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "report_id": self.report_id,
            "trigger_type": self.trigger_type.value,
            "strategy_id": self.strategy_id,
            "trigger_time": self.trigger_time.isoformat(),
            "window_start": self.window_start.isoformat(),
            "window_end": self.window_end.isoformat(),
            "trigger_event": self.trigger_event,
            "metrics_trajectory": self.metrics_trajectory,
            "triggered_rules": self.triggered_rules,
            "binding_constraints": self.binding_constraints,
            "regime_at_trigger": self.regime_at_trigger,
            "statistics": self.statistics,
            "replay_pointers": self.replay_pointers,
            "root_cause_analysis": self.root_cause_analysis,
            "recommendations": self.recommendations,
            "generated_at": self.generated_at.isoformat(),
            "version": self.version
        }

    def to_markdown(self) -> str:
        """è½¬æ¢ä¸º Markdown æŠ¥å‘Š"""
        lines = []
        lines.append(f"# Post-mortem Report: {self.report_id}\n")
        lines.append(f"**Strategy**: {self.strategy_id}")
        lines.append(f"**Trigger Type**: {self.trigger_type.value}")
        lines.append(f"**Trigger Time**: {self.trigger_time.isoformat()}\n")

        lines.append("## ğŸ“Š Trigger Event\n")
        lines.append(f"```json")
        lines.append(json.dumps(self.trigger_event, indent=2))
        lines.append(f"```\n")

        lines.append("## ğŸ“ˆ Metrics Trajectory\n")
        lines.append("| Time | Return | Drawdown | Volatility | Spike |")
        lines.append("|------|--------|----------|------------|-------|")
        for point in self.metrics_trajectory:
            lines.append(
                f"| {point['time']} | {point.get('return', 0):.2%} | "
                f"{point.get('drawdown', 0):.2%} | {point.get('volatility', 0):.2%} | "
                f"{point.get('spike', 0)} |"
            )
        lines.append("")

        lines.append("## ğŸ¯ Triggered Rules\n")
        for rule in self.triggered_rules:
            lines.append(f"- **{rule.get('rule_id', 'unknown')}**: {rule.get('description', '')}")
        lines.append("")

        lines.append("## ğŸŒ Market Regime at Trigger\n")
        lines.append(f"- Volatility Bucket: {self.regime_at_trigger.get('volatility_bucket', 'unknown')}")
        lines.append(f"- Trend Strength: {self.regime_at_trigger.get('trend_strength', 'unknown')}")
        lines.append(f"- Liquidity: {self.regime_at_trigger.get('liquidity_level', 'unknown')}")
        lines.append("")

        lines.append("## ğŸ” Root Cause Analysis\n")
        lines.append(f"### Primary Cause\n")
        lines.append(f"{self.root_cause_analysis.get('primary_cause', 'Unknown')}\n")

        lines.append(f"### Contributing Factors\n")
        for factor in self.root_cause_analysis.get('contributing_factors', []):
            lines.append(f"- {factor}")
        lines.append("")

        lines.append("## ğŸ’¡ Recommendations\n")
        for i, rec in enumerate(self.recommendations, 1):
            lines.append(f"{i}. {rec}")
        lines.append("")

        return "\n".join(lines)


@dataclass
class PostMortemConfig:
    """Post-mortem é…ç½®"""
    # æ—¶é—´çª—å£é…ç½®
    pre_trigger_window_seconds: int = 3600     # è§¦å‘å‰ 1 å°æ—¶
    post_trigger_window_seconds: int = 1800    # è§¦å‘å 30 åˆ†é’Ÿ

    # è¾“å‡ºé…ç½®
    output_dir: str = "outputs/postmortems"
    save_markdown: bool = True
    save_json: bool = True

    # æŒ‡æ ‡é‡‡æ ·é¢‘ç‡
    sample_frequency_seconds: int = 60         # æ¯åˆ†é’Ÿ

    # æœ€å°æŠ¥å‘Šé—´éš”ï¼ˆé˜²æ­¢é‡å¤ç”Ÿæˆï¼‰
    min_report_interval_seconds: int = 1800    # 30 åˆ†é’Ÿ


class PostMortemGenerator:
    """Post-mortem ç”Ÿæˆå™¨

    è‡ªåŠ¨åˆ†æé£é™©äº‹ä»¶å¹¶ç”Ÿæˆå½’å› æŠ¥å‘Šã€‚
    """

    def __init__(
        self,
        strategy_id: str,
        config: Optional[PostMortemConfig] = None,
        replay_data_path: Optional[str] = None
    ):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨

        Args:
            strategy_id: ç­–ç•¥ ID
            config: é…ç½®
            replay_data_path: Replay æ•°æ®è·¯å¾„
        """
        self.strategy_id = strategy_id
        self.config = config or PostMortemConfig()
        self.replay_data_path = replay_data_path

        # ä¿¡å·ç¼“å­˜ï¼ˆç”¨äºå›æº¯å†å²ï¼‰
        self.signal_history: List[RiskSignal] = []
        self.max_history_hours: int = 24

        # æœ€è¿‘ç”Ÿæˆçš„æŠ¥å‘Š
        self.last_report_time: Dict[PostMortemTriggerType, datetime] = {}

    def add_signal(self, signal: RiskSignal):
        """æ·»åŠ ä¿¡å·åˆ°å†å²

        Args:
            signal: é£é™©ä¿¡å·
        """
        self.signal_history.append(signal)

        # ä¿æŒå†å²é•¿åº¦
        cutoff_time = datetime.now() - timedelta(hours=self.max_history_hours)
        self.signal_history = [
            s for s in self.signal_history if s.timestamp >= cutoff_time
        ]

    def generate_from_gate_event(
        self,
        event: GatingEvent
    ) -> Optional[PostMortemReport]:
        """ä» gating äº‹ä»¶ç”Ÿæˆ post-mortem

        Args:
            event: Gating äº‹ä»¶

        Returns:
            PostMortemReport
        """
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”ŸæˆæŠ¥å‘Š
        if event.action not in ["GATE", "DISABLE"]:
            return None

        if not self._check_report_cooldown(PostMortemTriggerType.GATE_TRIGGERED):
            return None

        # æå–ä¸Šä¸‹æ–‡çª—å£
        window_signals = self._get_context_window(
            event.timestamp,
            self.config.pre_trigger_window_seconds,
            self.config.post_trigger_window_seconds
        )

        if not window_signals:
            return None

        # ç”ŸæˆæŠ¥å‘Š
        report = PostMortemReport(
            report_id=f"pm_gate_{event.strategy_id}_{event.timestamp.strftime('%Y%m%d%H%M%S')}",
            trigger_type=PostMortemTriggerType.GATE_TRIGGERED,
            strategy_id=event.strategy_id,
            trigger_time=event.timestamp,
            window_start=window_signals[0].timestamp,
            window_end=window_signals[-1].timestamp,
            trigger_event=event.to_dict(),
            metrics_trajectory=self._extract_metrics_trajectory(window_signals),
            triggered_rules=[{
                "rule_id": event.rule_id,
                "description": f"Gating rule triggered: {event.reason}",
                "action": event.action,
                "threshold": event.threshold,
                "current_value": event.current_value
            }],
            binding_constraints=[],
            regime_at_trigger=event.regime_features.to_dict() if event.regime_features else {},
            statistics=self._calculate_statistics(window_signals),
            replay_pointers=self._find_replay_pointers(event.timestamp),
            root_cause_analysis=self._analyze_root_cause(event, window_signals),
            recommendations=self._generate_recommendations(event, window_signals)
        )

        # ä¿å­˜æŠ¥å‘Š
        self._save_report(report)

        self.last_report_time[PostMortemTriggerType.GATE_TRIGGERED] = datetime.now()

        return report

    def generate_from_state_transition(
        self,
        transition: StateTransitionEvent
    ) -> Optional[PostMortemReport]:
        """ä»çŠ¶æ€è½¬æ¢ç”Ÿæˆ post-mortem

        Args:
            transition: çŠ¶æ€è½¬æ¢äº‹ä»¶

        Returns:
            PostMortemReport
        """
        # åªå¯¹ CRITICAL è½¬æ¢ç”ŸæˆæŠ¥å‘Š
        if transition.to_state != RiskState.CRITICAL:
            return None

        if not self._check_report_cooldown(PostMortemTriggerType.STATE_CRITICAL):
            return None

        # æå–ä¸Šä¸‹æ–‡çª—å£
        window_signals = self._get_context_window(
            transition.timestamp,
            self.config.pre_trigger_window_seconds,
            self.config.post_trigger_window_seconds
        )

        if not window_signals:
            return None

        # ç”ŸæˆæŠ¥å‘Š
        report = PostMortemReport(
            report_id=f"pm_state_{transition.strategy_id}_{transition.timestamp.strftime('%Y%m%d%H%M%S')}",
            trigger_type=PostMortemTriggerType.STATE_CRITICAL,
            strategy_id=transition.strategy_id,
            trigger_time=transition.timestamp,
            window_start=window_signals[0].timestamp,
            window_end=window_signals[-1].timestamp,
            trigger_event=transition.to_dict(),
            metrics_trajectory=self._extract_metrics_trajectory(window_signals),
            triggered_rules=[{
                "rule_id": transition.trigger_metric,
                "description": f"State transition: {transition.from_state.value} â†’ {transition.to_state.value}",
                "threshold": transition.threshold,
                "current_value": transition.trigger_value
            }],
            binding_constraints=[],
            regime_at_trigger=transition.context.get("regime_features", {}),
            statistics=self._calculate_statistics(window_signals),
            replay_pointers=self._find_replay_pointers(transition.timestamp),
            root_cause_analysis=self._analyze_root_cause(transition, window_signals),
            recommendations=self._generate_recommendations(transition, window_signals)
        )

        self._save_report(report)
        self.last_report_time[PostMortemTriggerType.STATE_CRITICAL] = datetime.now()

        return report

    def _get_context_window(
        self,
        trigger_time: datetime,
        pre_window_seconds: int,
        post_window_seconds: int
    ) -> List[RiskSignal]:
        """è·å–ä¸Šä¸‹æ–‡çª—å£å†…çš„ä¿¡å·

        Args:
            trigger_time: è§¦å‘æ—¶é—´
            pre_window_seconds: è§¦å‘å‰çª—å£
            post_window_seconds: è§¦å‘åçª—å£

        Returns:
            ä¿¡å·åˆ—è¡¨
        """
        window_start = trigger_time - timedelta(seconds=pre_window_seconds)
        window_end = trigger_time + timedelta(seconds=post_window_seconds)

        return [
            s for s in self.signal_history
            if window_start <= s.timestamp <= window_end
        ]

    def _extract_metrics_trajectory(
        self,
        signals: List[RiskSignal]
    ) -> List[Dict[str, float]]:
        """æå–æŒ‡æ ‡è½¨è¿¹

        Args:
            signals: ä¿¡å·åˆ—è¡¨

        Returns:
            æŒ‡æ ‡è½¨è¿¹
        """
        trajectory = []

        for signal in signals:
            # è®¡ç®—ç´¯è®¡æ”¶ç›Šï¼ˆç®€åŒ–ï¼‰
            cumulative_return = signal.rolling_returns.window_1d_return  # å ä½

            point = {
                "time": signal.timestamp.isoformat(),
                "return": cumulative_return,
                "drawdown": signal.drawdown.current_drawdown,
                "volatility": signal.stability.volatility_20d,
                "spike": float(signal.spike.recent_spike_count),
                "stability_score": signal.stability.stability_score
            }
            trajectory.append(point)

        return trajectory

    def _calculate_statistics(
        self,
        signals: List[RiskSignal]
    ) -> Dict[str, Any]:
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯

        Args:
            signals: ä¿¡å·åˆ—è¡¨

        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        if not signals:
            return {}

        drawdowns = [s.drawdown.current_drawdown for s in signals]
        volatilities = [s.stability.volatility_20d for s in signals]
        spikes = [s.spike.recent_spike_count for s in signals]

        return {
            "max_drawdown": max(drawdowns),
            "avg_drawdown": np.mean(drawdowns),
            "max_volatility": max(volatilities),
            "avg_volatility": np.mean(volatilities),
            "total_spikes": sum(spikes),
            "duration_hours": (signals[-1].timestamp - signals[0].timestamp).total_seconds() / 3600
        }

    def _find_replay_pointers(
        self,
        trigger_time: datetime,
        trade_id: Optional[str] = None,
        symbol: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """æŸ¥æ‰¾å¯¹åº”çš„ replay ç‰‡æ®µæŒ‡é’ˆ

        Args:
            trigger_time: è§¦å‘æ—¶é—´
            trade_id: äº¤æ˜“ IDï¼ˆå¯é€‰ï¼‰
            symbol: äº¤æ˜“å“ç§ï¼ˆå¯é€‰ï¼‰

        Returns:
            Replay æŒ‡é’ˆåˆ—è¡¨
        """
        try:
            # ä½¿ç”¨ ReplayLocator æŸ¥æ‰¾æ•°æ®
            locator = ReplayLocator(self.replay_data_path or "runs/")

            # æ„å»ºæŸ¥æ‰¾æ¡ä»¶
            conditions = {}
            if trade_id:
                conditions["trade_id"] = trade_id
            if symbol:
                conditions["symbol"] = symbol
            conditions["timestamp"] = trigger_time

            # æŸ¥æ‰¾å¯¹åº”çš„ replay æ•°æ®
            pointers = locator.find_replay_data(conditions)

            if pointers:
                return pointers

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›é»˜è®¤èŒƒå›´
            return [
                {
                    "replay_id": "unknown",
                    "segment_start": (trigger_time - timedelta(hours=1)).isoformat(),
                    "segment_end": (trigger_time + timedelta(minutes=30)).isoformat(),
                    "data_path": self.replay_data_path or "runs/",
                    "status": "fallback",
                    "reason": f"No replay data found for conditions: {conditions}"
                }
            ]

        except Exception as e:
            # å¼‚å¸¸æ—¶è¿”å›é™çº§ç»“æœ
            return [
                {
                    "replay_id": "error",
                    "segment_start": (trigger_time - timedelta(hours=1)).isoformat(),
                    "segment_end": (trigger_time + timedelta(minutes=30)).isoformat(),
                    "data_path": self.replay_data_path or "runs/",
                    "status": "error",
                    "reason": f"Failed to locate replay data: {str(e)}"
                }
            ]

    def _analyze_root_cause(
        self,
        event: Any,
        signals: List[RiskSignal]
    ) -> Dict[str, Any]:
        """åˆ†ææ ¹æœ¬åŸå› 

        Args:
            event: è§¦å‘äº‹ä»¶
            signals: ä¿¡å·åˆ—è¡¨

        Returns:
            æ ¹æœ¬åŸå› åˆ†æ
        """
        # åˆ†æä¸»è¦å› ç´ 
        factors = []

        # æ£€æŸ¥å›æ’¤
        max_dd = max((s.drawdown.current_drawdown for s in signals), default=0)
        if max_dd > 0.05:
            factors.append(f"Severe drawdown ({max_dd:.1%})")

        # æ£€æŸ¥æ³¢åŠ¨ç‡
        max_vol = max((s.stability.volatility_20d for s in signals), default=0)
        if max_vol > 0.03:
            factors.append(f"High volatility ({max_vol:.1%})")

        # æ£€æŸ¥ spike
        total_spikes = sum((s.spike.recent_spike_count for s in signals))
        if total_spikes > 5:
            factors.append(f"Multiple spikes ({total_spikes} events)")

        # æ£€æŸ¥å¸‚åœºçŠ¶æ€
        if signals:
            latest_signal = signals[-1]
            if latest_signal.regime.volatility_bucket == "high":
                factors.append("High volatility regime")
            if latest_signal.regime.trend_strength == "strong":
                factors.append("Strong trend regime")

        # åˆ¤å®šä¸»è¦æˆå› 
        primary_cause = factors[0] if factors else "Unknown"

        return {
            "primary_cause": primary_cause,
            "contributing_factors": factors,
            "confidence": "medium"  # low/medium/high
        }

    def _generate_recommendations(
        self,
        event: Any,
        signals: List[RiskSignal]
    ) -> List[str]:
        """ç”Ÿæˆå»ºè®®

        Args:
            event: è§¦å‘äº‹ä»¶
            signals: ä¿¡å·åˆ—è¡¨

        Returns:
            å»ºè®®åˆ—è¡¨
        """
        recommendations = []

        if not signals:
            return ["No data available for analysis"]

        latest_signal = signals[-1]

        # åŸºäº volatility çš„å»ºè®®
        if latest_signal.stability.volatility_20d > 0.03:
            recommendations.append("è€ƒè™‘æ”¶ç´§ gating é˜ˆå€¼ä»¥åº”å¯¹é«˜æ³¢åŠ¨ç¯å¢ƒ")

        # åŸºäº drawdown çš„å»ºè®®
        if latest_signal.drawdown.current_drawdown > 0.05:
            recommendations.append("ç›‘æ§å›æ’¤æ¢å¤æƒ…å†µï¼Œå¿…è¦æ—¶é™ä½ä»“ä½")

        # åŸºäº spike çš„å»ºè®®
        if latest_signal.spike.recent_spike_count > 5:
            recommendations.append("æ£€æŸ¥å¸‚åœºçŠ¶æ€ï¼Œè€ƒè™‘æš‚æ—¶é™ä½é£é™©æ•å£")

        # åŸºäº regime çš„å»ºè®®
        if latest_signal.regime.volatility_bucket == "high":
            recommendations.append("å½“å‰é«˜æ³¢åŠ¨ç¯å¢ƒï¼Œå»ºè®®å¯ç”¨ä¿å®ˆç­–ç•¥")

        # é€šç”¨å»ºè®®
        recommendations.append("ç»§ç»­ç›‘æ§é£é™©æŒ‡æ ‡ï¼Œå‡†å¤‡åº”æ€¥å“åº”")

        return recommendations

    def _check_report_cooldown(
        self,
        trigger_type: PostMortemTriggerType
    ) -> bool:
        """æ£€æŸ¥æŠ¥å‘Šå†·å´æ—¶é—´

        Args:
            trigger_type: è§¦å‘ç±»å‹

        Returns:
            Trueï¼ˆå¯ä»¥ç”Ÿæˆï¼‰æˆ– Falseï¼ˆå†·å´ä¸­ï¼‰
        """
        if trigger_type not in self.last_report_time:
            return True

        elapsed = (datetime.now() - self.last_report_time[trigger_type]).total_seconds()
        return elapsed >= self.config.min_report_interval_seconds

    def _save_report(self, report: PostMortemReport):
        """ä¿å­˜æŠ¥å‘Š

        Args:
            report: Post-mortem æŠ¥å‘Š
        """
        output_dir = Path(self.config.output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        # ä¿å­˜ JSON
        if self.config.save_json:
            json_file = output_dir / f"{report.report_id}.json"
            with open(json_file, 'w') as f:
                json.dump(report.to_dict(), f, indent=2, default=str)
            print(f"Post-mortem JSON saved: {json_file}")

        # ä¿å­˜ Markdown
        if self.config.save_markdown:
            md_file = output_dir / f"{report.report_id}.md"
            with open(md_file, 'w') as f:
                f.write(report.to_markdown())
            print(f"Post-mortem Markdown saved: {md_file}")


class ReplayLocator:
    """Replay æ•°æ®å®šä½å™¨

    æ ¹æ®äº¤æ˜“ IDã€æ—¶é—´æˆ³ã€å“ç§ç­‰æ¡ä»¶æŸ¥æ‰¾å¯¹åº”çš„ replay æ•°æ®ç‰‡æ®µã€‚
    """

    def __init__(self, runs_dir: str = "runs/"):
        """åˆå§‹åŒ–å®šä½å™¨

        Args:
            runs_dir: runs ç›®å½•è·¯å¾„
        """
        self.runs_dir = Path(runs_dir)
        self._replay_cache: Dict[str, ReplayOutput] = {}

    def find_replay_data(
        self,
        conditions: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """æŸ¥æ‰¾ replay æ•°æ®

        Args:
            conditions: æŸ¥æ‰¾æ¡ä»¶
                - trade_id: äº¤æ˜“ ID
                - timestamp: æ—¶é—´æˆ³ï¼ˆdatetimeï¼‰
                - symbol: äº¤æ˜“å“ç§
                - strategy_id: ç­–ç•¥ ID
                - run_id: è¿è¡Œ ID

        Returns:
            æ‰¾åˆ°çš„ replay æŒ‡é’ˆåˆ—è¡¨
        """
        pointers = []

        # æŒ‰ trade_id æŸ¥æ‰¾
        if "trade_id" in conditions:
            trade_id = conditions["trade_id"]
            pointers.extend(self._find_by_trade_id(trade_id))

        # æŒ‰ timestamp å’Œ symbol æŸ¥æ‰¾
        elif "timestamp" in conditions:
            timestamp = conditions["timestamp"]
            symbol = conditions.get("symbol")
            pointers.extend(self._find_by_time(timestamp, symbol))

        # æŒ‰ run_id æŸ¥æ‰¾
        elif "run_id" in conditions:
            run_id = conditions["run_id"]
            pointers.extend(self._find_by_run_id(run_id))

        return pointers

    def _find_by_trade_id(self, trade_id: str) -> List[Dict[str, Any]]:
        """æŒ‰äº¤æ˜“ ID æŸ¥æ‰¾

        Args:
            trade_id: äº¤æ˜“ ID

        Returns:
            replay æŒ‡é’ˆåˆ—è¡¨
        """
        pointers = []

        # æ‰«ææ‰€æœ‰ run ç›®å½•
        for replay in self._load_all_replays():
            # æŸ¥æ‰¾åŒ¹é…çš„ trade
            for trade in replay.trades:
                if trade.trade_id == trade_id:
                    pointers.append({
                        "replay_id": replay.run_id,
                        "strategy_id": replay.strategy_id,
                        "strategy_name": replay.strategy_name,
                        "trade_id": trade.trade_id,
                        "trade_timestamp": trade.timestamp.isoformat(),
                        "symbol": trade.symbol,
                        "side": trade.side,
                        "price": float(trade.price),
                        "quantity": trade.quantity,
                        "segment_start": (trade.timestamp - timedelta(hours=1)).isoformat(),
                        "segment_end": (trade.timestamp + timedelta(minutes=30)).isoformat(),
                        "data_path": str(self.runs_dir / replay.run_id),
                        "signal_id": trade.signal_id,
                        "status": "found"
                    })

        return pointers

    def _find_by_time(
        self,
        timestamp: datetime,
        symbol: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """æŒ‰æ—¶é—´æŸ¥æ‰¾

        Args:
            timestamp: æ—¶é—´æˆ³
            symbol: äº¤æ˜“å“ç§ï¼ˆå¯é€‰ï¼‰

        Returns:
            replay æŒ‡é’ˆåˆ—è¡¨
        """
        pointers = []

        # æ‰«ææ‰€æœ‰ run ç›®å½•
        for replay in self._load_all_replays():
            # æ£€æŸ¥æ—¶é—´èŒƒå›´æ˜¯å¦è¦†ç›–
            if not (replay.start_date <= timestamp.date() <= replay.end_date):
                continue

            # æŸ¥æ‰¾è¯¥æ—¶é—´é™„è¿‘çš„ steps
            nearby_steps = [
                s for s in replay.steps
                if abs((s.timestamp - timestamp).total_seconds()) < 3600  # 1å°æ—¶å†…
            ]

            if nearby_steps:
                # æ‰¾åˆ°æœ€è¿‘çš„ step
                nearest = min(nearby_steps, key=lambda s: abs((s.timestamp - timestamp).total_seconds()))

                # æŸ¥æ‰¾è¯¥æ—¶é—´çš„äº¤æ˜“
                relevant_trades = []
                for trade in replay.trades:
                    if abs((trade.timestamp - timestamp).total_seconds()) < 3600:
                        if symbol is None or trade.symbol == symbol:
                            relevant_trades.append({
                                "trade_id": trade.trade_id,
                                "symbol": trade.symbol,
                                "side": trade.side,
                                "price": float(trade.price),
                                "quantity": trade.quantity
                            })

                pointers.append({
                    "replay_id": replay.run_id,
                    "strategy_id": replay.strategy_id,
                    "strategy_name": replay.strategy_name,
                    "query_timestamp": timestamp.isoformat(),
                    "nearest_step_time": nearest.timestamp.isoformat(),
                    "segment_start": (timestamp - timedelta(hours=1)).isoformat(),
                    "segment_end": (timestamp + timedelta(minutes=30)).isoformat(),
                    "data_path": str(self.runs_dir / replay.run_id),
                    "relevant_trades": relevant_trades,
                    "status": "found"
                })

        return pointers

    def _find_by_run_id(self, run_id: str) -> List[Dict[str, Any]]:
        """æŒ‰è¿è¡Œ ID æŸ¥æ‰¾

        Args:
            run_id: è¿è¡Œ ID

        Returns:
            replay æŒ‡é’ˆåˆ—è¡¨
        """
        replay_path = self.runs_dir / run_id

        if not replay_path.exists():
            return [{
                "replay_id": run_id,
                "status": "not_found",
                "reason": f"Run directory not found: {replay_path}"
            }]

        try:
            replay = ReplayOutput.from_directory(replay_path)

            return [{
                "replay_id": replay.run_id,
                "strategy_id": replay.strategy_id,
                "strategy_name": replay.strategy_name,
                "start_date": replay.start_date.isoformat(),
                "end_date": replay.end_date.isoformat(),
                "data_path": str(replay_path),
                "total_trades": len(replay.trades),
                "total_steps": len(replay.steps),
                "status": "found"
            }]

        except Exception as e:
            return [{
                "replay_id": run_id,
                "status": "error",
                "reason": f"Failed to load replay: {str(e)}"
            }]

    def _load_all_replays(self) -> List[ReplayOutput]:
        """åŠ è½½æ‰€æœ‰ replay æ•°æ®

        Returns:
            ReplayOutput åˆ—è¡¨
        """
        if not self._replay_cache:
            try:
                self._replay_cache = {
                    r.run_id: r for r in load_replay_outputs(str(self.runs_dir))
                }
            except Exception as e:
                print(f"Warning: Failed to load replays: {e}")

        return list(self._replay_cache.values())

    def get_signal_context(
        self,
        run_id: str,
        timestamp: datetime
    ) -> Dict[str, Any]:
        """è·å–ä¿¡å·ä¸Šä¸‹æ–‡

        æŸ¥æ‰¾æŒ‡å®š run ä¸­æŒ‡å®šæ—¶é—´ç‚¹çš„ä¿¡å·çŠ¶æ€ã€‚

        Args:
            run_id: è¿è¡Œ ID
            timestamp: æ—¶é—´æˆ³

        Returns:
            ä¿¡å·ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        # æŸ¥æ‰¾ replay
        pointers = self._find_by_run_id(run_id)

        if not pointers or pointers[0]["status"] != "found":
            return {
                "status": "not_found",
                "reason": f"Replay not found for run_id: {run_id}"
            }

        replay = self._replay_cache.get(run_id)
        if not replay:
            return {
                "status": "error",
                "reason": "Replay not in cache"
            }

        # æŸ¥æ‰¾æœ€è¿‘çš„ step
        nearest_step = None
        min_diff = float('inf')

        for step in replay.steps:
            diff = abs((step.timestamp - timestamp).total_seconds())
            if diff < min_diff:
                min_diff = diff
                nearest_step = step

        if nearest_step is None:
            return {
                "status": "not_found",
                "reason": "No steps found in replay"
            }

        # æŸ¥æ‰¾ç›¸å…³äº¤æ˜“
        nearby_trades = [
            t for t in replay.trades
            if abs((t.timestamp - timestamp).total_seconds()) < 3600
        ]

        return {
            "status": "found",
            "step": {
                "timestamp": nearest_step.timestamp.isoformat(),
                "step_pnl": float(nearest_step.step_pnl),
                "equity": float(nearest_step.equity),
                "signal_state": nearest_step.signal_state
            },
            "nearby_trades": [
                {
                    "trade_id": t.trade_id,
                    "timestamp": t.timestamp.isoformat(),
                    "symbol": t.symbol,
                    "side": t.side,
                    "price": float(t.price),
                    "quantity": t.quantity
                }
                for t in nearby_trades
            ],
            "config": {
                "cost_model": nearest_step.cost_model,
                "slippage": nearest_step.slippage
            }
        }

    def clear_cache(self) -> None:
        """æ¸…é™¤ç¼“å­˜"""
        self._replay_cache.clear()
