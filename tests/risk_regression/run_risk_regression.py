"""
CI Runner for Risk Regression Tests (SPL-4c)

Runs all risk regression tests and generates PASS/FAIL report.
"""

import sys
import argparse
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

from analysis.baseline_manager import BaselineManager
from analysis.replay_schema import load_replay_outputs
from tests.risk_regression.risk_baseline_test import RiskBaselineTests, TestResult


def generate_markdown_report(results: Dict[str, Any], output_path: Path):
    """Generate markdown report

    Args:
        results: Test results dictionary
        output_path: Path to save report
    """
    lines = []

    lines.append("# Risk Regression Test Report\n")
    lines.append(f"**Generated**: {datetime.now().isoformat()}\n")
    lines.append(f"**Total Strategies**: {results.get('total_strategies', 0)}\n")
    lines.append(f"**Overall Status**: {results.get('overall_status', 'UNKNOWN')}\n")

    # Summary
    total_tests = results.get('total_tests', 0)
    passed_tests = results.get('passed_tests', 0)
    failed_tests = results.get('failed_tests', 0)
    skipped_tests = results.get('skipped_tests', 0)

    lines.append("\n## Summary\n")
    lines.append(f"- **Total Tests**: {total_tests}")
    lines.append(f"- **Passed**: {passed_tests}")
    lines.append(f"- **Failed**: {failed_tests}")
    lines.append(f"- **Skipped**: {skipped_tests}")
    lines.append(f"\n**Pass Rate**: {passed_tests/total_tests*100 if total_tests > 0 else 0:.1f}%\n")

    # Strategy details
    lines.append("\n## Strategy Results\n")

    for strategy_result in results.get('strategies', []):
        strategy_id = strategy_result.get('strategy_id', 'unknown')
        status = strategy_result.get('status', 'UNKNOWN')

        status_emoji = {
            "PASS": "✅",
            "FAIL": "❌",
            "SKIP": "⏭️",
            "ERROR": "⚠️"
        }.get(status, "❓")

        lines.append(f"\n### {status_emoji} {strategy_id}\n")
        lines.append(f"**Status**: {status}\n")

        # Test results
        test_results = strategy_result.get('tests', {})
        if test_results:
            lines.append("| Test | Status | Message |")
            lines.append("|------|--------|----------|")

            for test_name, test_result in test_results.items():
                if test_name.startswith("_"):
                    continue
                test_status = test_result.get('status', 'UNKNOWN')
                test_message = test_result.get('message', '')
                # Truncate long messages
                if len(test_message) > 60:
                    test_message = test_message[:57] + "..."
                lines.append(f"| {test_name} | {test_status} | {test_message} |")

        # Details
        if strategy_result.get('details'):
            lines.append(f"\n<details>")
            lines.append(f"<summary>Details</summary>\n")
            lines.append(f"```json")
            lines.append(json.dumps(strategy_result['details'], indent=2))
            lines.append(f"```\n")
            lines.append(f"</details>")

    # Footer
    lines.append("\n---\n")
    lines.append("*Generated by SPL-4c Risk Regression Tests*\n")

    report = "\n".join(lines)
    output_path.write_text(report, encoding='utf-8')


def run_risk_regression(
    replay_dir: str = "runs",
    baseline_dir: str = "baselines/risk",
    output_dir: str = "reports/risk_regression",
    tolerance_pct: float = 0.02,
    fail_on_regression: bool = True
) -> Dict[str, Any]:
    """Run all risk regression tests

    Args:
        replay_dir: Directory containing current replay outputs
        baseline_dir: Directory containing frozen baselines
        output_dir: Output directory for reports
        tolerance_pct: Allowed tolerance for comparisons (default 2%)
        fail_on_regression: Exit with error code on FAIL (default True)

    Returns:
        Results dictionary
    """
    print("="*70)
    print("SPL-4c: Risk Regression Tests")
    print("="*70)
    print(f"\nReplay directory: {replay_dir}")
    print(f"Baseline directory: {baseline_dir}")
    print(f"Output directory: {output_dir}")
    print(f"Tolerance: {tolerance_pct*100}%\n")

    # Create output directory
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    # Load baselines
    print("Loading baselines...")
    manager = BaselineManager(baseline_dir=baseline_dir)
    snapshot = manager.load_all_baselines()

    if not snapshot.baselines:
        print("Warning: No baselines found. Nothing to test.")
        return {
            "overall_status": "SKIP",
            "total_strategies": 0,
            "total_tests": 0,
            "passed_tests": 0,
            "failed_tests": 0,
            "skipped_tests": 0,
            "strategies": []
        }

    print(f"Loaded {len(snapshot.baselines)} baselines\n")

    # Load current replays
    print("Loading current replays...")
    current_replays = load_replay_outputs(replay_dir)
    print(f"Loaded {len(current_replays)} current replays\n")

    # Map replays by strategy_id
    replay_map = {r.strategy_id: r for r in current_replays}

    # Run tests
    results = {
        "overall_status": "PASS",
        "total_strategies": len(snapshot.baselines),
        "total_tests": 0,
        "passed_tests": 0,
        "failed_tests": 0,
        "skipped_tests": 0,
        "strategies": []
    }

    test_suite = RiskBaselineTests(tolerance_pct=tolerance_pct)

    for baseline in snapshot.baselines:
        print(f"\nTesting: {baseline.baseline_id}")
        print("-" * 70)

        strategy_result = {
            "baseline_id": baseline.baseline_id,
            "strategy_id": baseline.strategy_id,
            "run_id": baseline.run_id,
            "status": "PASS",
            "tests": {},
            "details": {}
        }

        # Find corresponding current replay
        current_replay = replay_map.get(baseline.strategy_id)

        if current_replay is None:
            print(f"  ⏭️  SKIP: No current replay found for {baseline.strategy_id}")
            strategy_result["status"] = "SKIP"
            strategy_result["tests"]["_error"] = {
                "status": "SKIP",
                "message": f"No current replay found for strategy {baseline.strategy_id}"
            }
            results["skipped_tests"] += 1
            results["strategies"].append(strategy_result)
            continue

        # Run all 5 tests
        tests = [
            ("worst_window_non_drift", "C2.1: Worst-Window Non-Drift"),
            ("structural_similarity", "C2.2: Structural Similarity"),
            ("envelope_non_regression", "C2.3: Envelope Non-Regression"),
            ("rule_trigger_sanity", "C2.4: Rule Trigger Sanity"),
            ("replay_determinism", "C2.5: Replay Determinism")
        ]

        for test_method, test_name in tests:
            try:
                print(f"  Running: {test_name}...")
                test_func = getattr(test_suite, f"test_{test_method}")
                result = test_func(baseline, current_replay)

                strategy_result["tests"][test_method] = result.to_dict()
                results["total_tests"] += 1

                if result.status == "PASS":
                    print(f"    ✅ PASS: {result.message}")
                    results["passed_tests"] += 1
                elif result.status == "FAIL":
                    print(f"    ❌ FAIL: {result.message}")
                    results["failed_tests"] += 1
                    strategy_result["status"] = "FAIL"
                    results["overall_status"] = "FAIL"
                elif result.status == "SKIP":
                    print(f"    ⏭️  SKIP: {result.message}")
                    results["skipped_tests"] += 1

            except Exception as e:
                print(f"    ⚠️  ERROR: {str(e)}")
                strategy_result["tests"][test_method] = {
                    "status": "ERROR",
                    "message": str(e)
                }
                results["failed_tests"] += 1
                strategy_result["status"] = "ERROR"
                results["overall_status"] = "FAIL"

        results["strategies"].append(strategy_result)

        print(f"\n  Result: {strategy_result['status']}")

    # Print summary
    print("\n" + "="*70)
    print("SUMMARY")
    print("="*70)
    print(f"Overall Status: {results['overall_status']}")
    print(f"Total Tests: {results['total_tests']}")
    print(f"Passed: {results['passed_tests']}")
    print(f"Failed: {results['failed_tests']}")
    print(f"Skipped: {results['skipped_tests']}")
    print(f"Pass Rate: {results['passed_tests']/results['total_tests']*100 if results['total_tests'] > 0 else 0:.1f}%")
    print("="*70)

    # Save reports
    json_path = output_path / "report.json"
    json_path.write_text(json.dumps(results, indent=2), encoding='utf-8')
    print(f"\n✓ JSON report saved: {json_path}")

    md_path = output_path / "report.md"
    generate_markdown_report(results, md_path)
    print(f"✓ Markdown report saved: {md_path}")

    # Exit with error if regression detected
    if fail_on_regression and results["overall_status"] in ["FAIL", "ERROR"]:
        print("\n❌ Risk regression detected! Exiting with error.")
        sys.exit(1)

    return results


def main():
    """CLI entry point"""
    parser = argparse.ArgumentParser(
        description="Run SPL-4c risk regression tests"
    )
    parser.add_argument(
        "--replay-dir",
        default="runs",
        help="Directory containing current replay outputs"
    )
    parser.add_argument(
        "--baseline-dir",
        default="baselines/risk",
        help="Directory containing frozen baselines"
    )
    parser.add_argument(
        "--output-dir",
        default="reports/risk_regression",
        help="Output directory for reports"
    )
    parser.add_argument(
        "--tolerance",
        type=float,
        default=0.02,
        help="Allowed tolerance for comparisons (default: 0.02 = 2%%)"
    )
    parser.add_argument(
        "--no-fail",
        action="store_true",
        help="Don't exit with error on regression"
    )

    args = parser.parse_args()

    run_risk_regression(
        replay_dir=args.replay_dir,
        baseline_dir=args.baseline_dir,
        output_dir=args.output_dir,
        tolerance_pct=args.tolerance,
        fail_on_regression=not args.no_fail
    )


if __name__ == "__main__":
    main()
